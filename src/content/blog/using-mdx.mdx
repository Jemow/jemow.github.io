---
title: 'OpenGL ES Renderer'
description: 'A technical devlog of my 2nd-year project: building a real-time 3D scene using OpenGL ES.'
pubDate: 2026-02-03
updatedDate: 2026-02-04
heroImage: /src/assets/cars1_tuner_scene.png
author: Jemo
tags:
  - Engine
  - Graphics
  - OpenGL
---

# Introduction

Dans le cadre de mon projet de 2√®me ann√©e √† la SAE Institute Gen√®ve,
j'ai eu pour mission de construire une sc√®ne 3D en utilisant C++ et OpenGL ES 3.0. 

Ce projet a √©t√© l'occasion de voir le fonctionnement bas niveau du GPU. 
Dans ce blogpost, je vais pr√©senter les techniques de rendu, en me concentrant 
sur les concepts importants plut√¥t que sur les d√©tails d'impl√©mentation.
Pour aller plus en pronfondeur , vous pouvez lire [LearnOpenGL](https://learnopengl.com/) qui
est l'endroit qui ma servit de r√©f√©rences tout du long du module.

# Engine

## Model

Tout commence par l'importation de la g√©om√©trie. J'ai opt√© pour des models 
format standard Wavefront (.obj) pour leur simplicit√©.
Pour la sc√®ne, j'ai choisi des mod√®les iconiques du film Cars (notamment Wingo). 
Cependant, pour obtenir un rendu r√©aliste dans mon pipeline, j'ai g√©n√©rer des 
textures compatibles via PBR Forge car les models n'avaient que leur textures.

![Wingo](/src/assets/wingo.png)

Pour l'importation des mod√®les 3D, j'ai utilis√© la library [Assimp](https://github.com/assimp/assimp)
qui permet de g√©n√©rer les vertices, indices et materials.

Lors du chargement, j'utilise des flags pour transformer les donn√©es : aiProcess_Triangulate
pour avoir des triangles et aiProcess_CalcTangentSpace pour calculer les tangentes n√©cessaires 
au Normal Mapping.
```cpp
Assimp::Importer importer;

const aiScene* scene = importer.ReadFile(
    path,
    aiProcess_Triangulate |
    aiProcess_FlipUVs |
    aiProcess_CalcTangentSpace
);
```
Une fois le fichier lu, la fonction r√©cursive ProcessNode parcourt la 
hi√©rarchie du mod√®le pour extraire chaque partie de la voiture.
```cpp
void Model::ProcessNode(const aiNode* node, const aiScene* scene)
{
    for (unsigned int i = 0; i < node->mNumMeshes; i++)
    {
        const aiMesh* mesh = scene->mMeshes[node->mMeshes[i]];
        sub_meshes_.push_back(ProcessMesh(mesh, scene));
    }

    for (unsigned int i = 0; i < node->mNumChildren; i++)
        ProcessNode(node->mChildren[i], scene);
}
````
La m√©thode ProcessMesh s'occupe de convertir les donn√©es d'Assimp vers mes propres
structures de donn√©es. C'est ici que je r√©cup√®re les positions, normales et 
UVs pour cr√©er mes sommets.

## Meshes & Vertex Attributes

Une fois les donn√©s du mesh charg√©es, elles doivent √™tre envoy√©es au GPU. 
Pour que le shader puisse interpr√©ter correctement les donn√©es brutes,
j'utilise une abstraction VertexBufferAttribute contenant toutes les informations
n√©cessaires pour d√©crire un vertex.
```cpp
struct VertexBufferAttribute {
  GLuint location;
  GLint size;
  GLenum type;
  GLsizei stride;
  size_t offset;
};
```
Cela permet d'expliquer √† OpenGL la structure de mon sommet : o√π se trouve la position, 
la normale, les UVs, ainsi que les tangentes et bitangentes indispensables pour le Normal Mapping.
J'utilise offsetof pour calculer automatiquement les d√©calages dans la m√©moire.
```cpp
constexpr common::VertexBufferAttribute attributes[] = {
    { 0, 3, GL_FLOAT, sizeof(Vertex), offsetof(Vertex, Position) },
    { 1, 3, GL_FLOAT, sizeof(Vertex), offsetof(Vertex, Normal) },
    { 2, 2, GL_FLOAT, sizeof(Vertex), offsetof(Vertex, TexCoords) },
    { 3, 3, GL_FLOAT, sizeof(Vertex), offsetof(Vertex, Tangent) },
    { 4, 3, GL_FLOAT, sizeof(Vertex), offsetof(Vertex, Bitangent) }
};
vertex_input_.BindVertexBuffer(vertex_buffer_, attributes);
```

## Materials & Textures

![Textures](/src/assets/textures.png)
Pour charger les textures associ√©es au mod√®le, j'ai cr√©√© une m√©thode LoadMaterial. Elle utilise une
petite lambda bien pratique pour v√©rifier si une texture existe dans le fichier .obj (via Assimp)
et la charger automatiquement dans le bon slot de ma structure Material.

```cpp
Material Model::LoadMaterial(const aiMaterial* mat) const
{
    Material m;

    auto LoadTex = [&](const aiTextureType type, common::Texture& dst)
    {
        if (mat->GetTextureCount(type) > 0)
        {
            aiString file;
            mat->GetTexture(type, 0, &file);

            const std::string full = directory_ + file.C_Str();
            dst.Load(full);
        }
    };

    LoadTex(aiTextureType_DIFFUSE,  m.diffuseMap);
    LoadTex(aiTextureType_NORMALS,  m.normalMap);
    LoadTex(aiTextureType_EMISSIVE, m.emissiveMap);
    LoadTex(aiTextureType_SPECULAR, m.metallicMap);
    LoadTex(aiTextureType_SHININESS, m.roughnessMap);
    LoadTex(aiTextureType_AMBIENT, m.aoMap);

    return m;
}
```
Une fois les mat√©riaux charg√©s, il faut les envoyer au shader. 
Pour simplifier cela, j'utilise la m√©thode SetTexture de l'abstraction Pipeline.

Cette m√©thode fait deux choses importantes : elle informe le shader de l'unit√© de
texture √† utiliser (via un uniform int) et elle active cette 
unit√© pour y lier la texture correspondante.
```cpp
void Pipeline::SetTexture(std::string_view name, const Texture& texture, int texture_unit) {
  SetInt(name.data(), texture_unit);
  glActiveTexture(GL_TEXTURE0 + texture_unit);
  texture.Bind();
}
```
Dans la m√©thode Bind de la class Material, j'utilise cette abstraction pour lier toutes les maps
(BaseColor, Normale, Metallic, etc.) de mani√®re organis√©e. J'envoie aussi des bool√©ens pour 
que le shader sache si une texture est pr√©sente ou s'il doit utiliser une valeur par d√©faut.
```cpp
void Bind(common::Pipeline& pipeline) const {
    pipeline.SetTexture("diffuseMap",   diffuseMap,   0);
    pipeline.SetTexture("normalMap",    normalMap,    1);
    pipeline.SetTexture("emissiveMap",  emissiveMap,  2);
    pipeline.SetTexture("metallicMap",  metallicMap,  3);
    pipeline.SetTexture("roughnessMap", roughnessMap, 4);
    pipeline.SetTexture("aoMap",        aoMap,        5);


    pipeline.SetBool("useNormalMap", normalMap.get().texture_name != 0);
    pipeline.SetBool("useMetallicMap", metallicMap.get().texture_name != 0);
    // ...
}
```
Puis la classe common::Texture s'occupe de la partie technique avec stb_image.

## Normal Mapping

Le Normal Mapping sert √† simuler du relief sur la carrosserie des voitures.
Le souci, c'est que les normales d'une "Normal Map" sont dans l'espace tangent (local √† la face).
Pour les utiliser dans l'espace monde pour la lumi√®re, il faut une matrice de transition : 
la matrice TBN.

Je fais le calcul dans le Vertex Shader avec les attributs aNormal et aTangent d'Assimp.
```cpp
  mat3 normalMatrix = mat3(transpose(inverse(finalModel)));
  vec3 T = normalize(normalMatrix * aTangent);
  vec3 N = normalize(normalMatrix * aNormal);
  T = normalize(T - dot(T, N) * N);
  vec3 B = cross(N, T);
```
J'utilise ici le proc√©d√© de Gram-Schmidt pour √™tre s√ªr que la tangente reste parfaitement
orthogonale √† la normale. Ensuite, je calcule la bitangente avec un Cross.
Ce calcul me permet de passer de l'espace tangent √† l'espace monde (World Space), 
l√† o√π je fais tous mes calculs de lumi√®re.

## Back Face Culling

Pour optimiser le rendu, j'ai appris 2 techniques de culling.
La premi√®re est le Back-face Culling. C'est une technique tr√®s rapide √†
impl√©menter qui demande au GPU de ne pas dessiner les faces arri√®re des objets 
Cela r√©duit le nombre de triangles √† traiter sans affecter le visuel final.
```cpp
glEnable(GL_CULL_FACE);
glCullFace(GL_BACK);
glFrontFace(GL_CCW); // D√©finit le sens de lecture des triangles (Counter-Clockwise)
```
Dans cette image, notre cam√©ra se trouve √† l'int√©rieur de la voiture (Wingo).
Avec le Back-Face Culling activ√©, toutes les faces de la carrosserie qui pointent
vers l'ext√©rieur ne sont pas rendues. C'est pour cette raison que l'on peut voir 
√† travers le mod√®le depuis l'int√©rieur.
![Back Face Culling example](/src/assets/back_face_culling.png)
Pour tester visuellement le concept, on peut √©galement inverser le mode en Front-Face Culling :
dans ce cas, le GPU n'affichera que l'int√©rieur (les faces arri√®re) et masquera l'ext√©rieur 
de la voiture.

## Frustum Culling

La deuxi√®me technique est le Frustum Culling. Contrairement au Back-face qui 
travaille au niveau des triangles, le Frustum Culling intervient au niveau des mod√®les. 
L'objectif est de ne pas envoyer au GPU les objets qui se trouvent en dehors du champ
de vision de la cam√©ra.

Le champ de vision est repr√©sent√© par une pyramide tronqu√©e (le Frustum) d√©finie par six plans : 
le Near plane, le Far plane, ainsi que les plans haut, bas, gauche et droite.
![Frsutum Camera example](/src/assets/frustum_example.png)
Pour savoir si un objet doit √™tre rendu, je v√©rifie s'il intersecte cette zone de vision. 
Chaque mod√®le poss√®de un membre AABB (Axis-Aligned Bounding Box) qui
est pr√©-calcul√© lors du Model::Load.

Pour mettre cela en pratique, j'ai cr√©√© une classe Frustum tr√®s simple. 
Elle contient les six plans de la pyramide de vue et poss√®de une m√©thode IsOnFrustum. 
Cette fonction prend l'AABB d'un mod√®le et sa modelMatrix pour d√©terminer
instantan√©ment si l'objet est visible ou non.
```cpp
class Frustum
{
public:
    void Update(const glm::mat4& viewProjection);
    bool IsOnFrustum(const AABB& box, const glm::mat4& modelMatrix) const;

private:
    std::array<Plane, 6> planes_;
};
```
J'ai int√©gr√© cette logique directement dans l'abstraction de ma Camera.
En combinant la matrice de projection et la matrice de vue, la cam√©ra peut 
g√©n√©rer un Frustum √† jour √† chaque frame.
```cpp
Frustum Camera::get_frustum() const
{
    Frustum frustum;
    frustum.Update(projection_matrix_ * get_view_matrix());
    return frustum;
}
```

## GPU Instancing

L'Instancing est une autre technique d'optimisation. C'est ce qui permet
d'afficher des centaines d'objets identiques, comme mes c√¥nes de chantier,
en un seul draw call. Au lieu d'envoyer chaque c√¥ne un par un,
j'envoie un tableau de matrices de transformation au GPU.
![Instancing Cone example](/src/assets/instancing_example.png)
Pour que cela fonctionne, je dois configurer des attributs de sommets particuliers. 
Une matrice mat4 occupant 4 slots cons√©cutifs (locations 5 √† 8), j'utilise glVertexAttribDivisor.
Cela indique √† OpenGL de ne passer √† la matrice suivante qu'apr√®s avoir dessin√© un objet complet, 
et pas apr√®s chaque sommet.
```cpp
void Mesh::SetupInstancing(const common::VertexBuffer& instance_buffer) {
    vertex_input_.Bind();
    instance_buffer.Bind();

    std::size_t vec4Size = sizeof(glm::vec4);
    glEnableVertexAttribArray(5);
    glVertexAttribPointer(5, 4, GL_FLOAT, GL_FALSE, 4 * vec4Size, (void*)0);
    glEnableVertexAttribArray(6);
    glVertexAttribPointer(6, 4, GL_FLOAT, GL_FALSE, 4 * vec4Size, (void*)(1 * vec4Size));
    glEnableVertexAttribArray(7);
    glVertexAttribPointer(7, 4, GL_FLOAT, GL_FALSE, 4 * vec4Size, (void*)(2 * vec4Size));
    glEnableVertexAttribArray(8);
    glVertexAttribPointer(8, 4, GL_FLOAT, GL_FALSE, 4 * vec4Size, (void*)(3 * vec4Size));

    glVertexAttribDivisor(5, 1);
    glVertexAttribDivisor(6, 1);
    glVertexAttribDivisor(7, 1);
    glVertexAttribDivisor(8, 1);
}
```
C√¥t√© Shader, la logique est tr√®s simple. Si l'instancing est activ√©, j'utilise la matrice 
d'instance re√ßue en attribut (aInstanceMatrix) √† la place de la matrice de mod√®le classique.
Cela permet de positionner chaque c√¥ne √† sa coordonn√©e unique tout en utilisant la m√™me g√©om√©trie.
```cpp
layout (location = 5) in mat4 aInstanceMatrix;
uniform bool useInstancing;

void main() {
    mat4 finalModel = useInstancing ? aInstanceMatrix : model;
    vec4 worldPos = finalModel * vec4(aPos, 1.0);
    
    gl_Position = projection * view * worldPos;
}
```
Enfin, pour le rendu, il suffit d'appeler glDrawElementsInstanced. Mon abstraction Model se charge de 
r√©percuter cet appel sur tous ses sub meshes.

Pour valider que l'instancing fonctionne correctement, j'ai utilis√© RenderDoc afin d'inspecter les appels GPU.
Sur la capture ci-dessous, on peut voir l'appel glDrawElementsInstanced. Au lieu de dessiner 
un seul c√¥ne, le GPU en g√©n√®re 4 en un seul passage en utilisant les donn√©es de mon instance 
buffer (√©videmment on peut en instancier bien plus que 4 üòÖ).
![Instancing RenderDoc example](/src/assets/instancing_renderdoc.png)
C'est cette technique qui permet de garder un framerate √©lev√© m√™me avec une sc√®ne charg√©e d'objets r√©p√©titifs.

## Deferred Rendering

Le Deferred Rendering est le c≈ìur de mon pipeline de rendu. Contrairement au rendu classique o√π l'on calcule la lumi√®re 
pour chaque objet au moment de le dessiner, le Deferred repose sur une s√©paration claire entre la 
r√©cup√©ration des donn√©es g√©om√©triques et le calcul final de l'image. Cette architecture m'a permis 
d'int√©grer efficacement de nombreuses passes de rendu (Shadows, SSAO, Bloom) sans surcharger le GPU.
![Deferred Overview](/src/assets/deferred_overview.png)

## Geometry Buffer

L'objectif est d'√©viter de calculer l'√©clairage de pixels qui seront finalement cach√©s par d'autres objets devant eux. 
Pour cela, on utilise un G-Buffer.

Le G-Buffer est un ensemble de textures dans lesquelles on stocke les informations g√©om√©triques de la sc√®ne lors de la "Geometry Pass".
Au lieu de dessiner une image finale, on remplit plusieurs buffers simultan√©ment :
- Positions
- Normales
- Albedo (BaseColor)
- Emissive

Pour que cela fonctionne techniquement, j'ai cr√©√© une classe GBuffer. L'√©l√©ment le plus important
est l'initialisation des textures via une lambda createTex. Cela me permet de configurer proprement
le MRT (Multiple Render Targets) en attachant chaque buffer (Position, Normale, Albedo, Emissive)
√† un slot sp√©cifique.

```cpp
auto createTex = [&](GLuint& id, const GLint internal, const GLenum type, const int attach) {
    glGenTextures(1, &id);
    glBindTexture(GL_TEXTURE_2D, id);
    glTexImage2D(GL_TEXTURE_2D, 0, internal, width, height, 0, GL_RGBA, type, NULL);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
    glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
    glFramebufferTexture2D(GL_FRAMEBUFFER, GL_COLOR_ATTACHMENT0 + attach, GL_TEXTURE_2D, id, 0);
};

createTex(g_position_, GL_RGBA16F, GL_FLOAT, 0);
createTex(g_normal_, GL_RGBA16F, GL_FLOAT, 1);
createTex(g_albedo_, GL_RGBA, GL_UNSIGNED_BYTE, 2);
createTex(g_emissive_, GL_RGBA16F, GL_FLOAT, 3);
```
Une autre m√©thode cruciale est BlitDepthToDefault. Comme le Deferred Rendering s'effectue sur un simple 
Quad √† la fin, on perdrait normalement les informations de profondeur. Cette fonction me permet de 
copier le buffer de profondeur du G-Buffer vers le buffer par d√©faut du syst√®me. 
Cela √©vite que la Skybox ou d'autres objets couvrent les voitures.
```cpp
void GBuffer::BlitDepthToDefault(const unsigned int width, unsigned int const height) const
{
    glBindFramebuffer(GL_READ_FRAMEBUFFER, g_buffer_);
    glBindFramebuffer(GL_DRAW_FRAMEBUFFER, 0);
    glBlitFramebuffer(0, 0, width_, height_, 0, 0, width, height, GL_DEPTH_BUFFER_BIT, GL_NEAREST);
    glBindFramebuffer(GL_FRAMEBUFFER, 0);
}
```
Voici le rendu de mes diff√©rents buffers tel qu'on peut les observer lors d'une capture sur RenderDoc :
- Positions : Chaque pixel stocke ses coordonn√©es mondiales (XYZ).
![GBuffer Position](/src/assets/gbuffer_position.png)
- Normales : L'orientation de chaque surface.
![GBuffer Normal](/src/assets/gbuffer_normal.png)
- Albedo : Les couleurs brutes des textures.
![GBuffer Albedo](/src/assets/gbuffer_albedo.png)
- Emissive : Uniquement les zones qui √©mettent de la lumi√®re.
![GBuffer Emissive](/src/assets/gbuffer_emissive.png)

## Shadow Pass

Avant d'attaquer le G-Buffer, je dois g√©n√©rer une Shadow Map pour calculer les ombres de ma lumi√®re directionnelle.
Le principe est de faire une passe de rendu du point de vue de la lumi√®re pour stocker
la profondeur de la sc√®ne dans une texture.

Dans ma classe ShadowMap, j'utilise un FBO avec uniquement un GL_DEPTH_ATTACHMENT.
Comme je n'ai pas besoin de couleurs ici, je d√©sactive explicitement les buffers 
de lecture et d'√©criture.
```cpp
glGenFramebuffers(1, &fbo_);
glGenTextures(1, &depth_map_texture_);

glBindTexture(GL_TEXTURE_2D, depth_map_texture_);
glTexImage2D(GL_TEXTURE_2D, 0, GL_DEPTH_COMPONENT24, width_, height_, 0, GL_DEPTH_COMPONENT, GL_UNSIGNED_INT, NULL);

glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_NEAREST);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP_TO_EDGE);
glTexParameteri(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP_TO_EDGE);

glBindFramebuffer(GL_FRAMEBUFFER, fbo_);
glFramebufferTexture2D(GL_FRAMEBUFFER, GL_DEPTH_ATTACHMENT, GL_TEXTURE_2D, depth_map_texture_, 0);

constexpr GLenum drawBuffers[] = { GL_NONE };
glDrawBuffers(1, drawBuffers);
glReadBuffer(GL_NONE);

glBindFramebuffer(GL_FRAMEBUFFER, 0);
```
Pour une lumi√®re directionnelle, j'utilise une projection orthographique. 
La matrice lightSpaceMatrix combine cette projection avec une vue positionn√©e face √† la sc√®ne.
```cpp
const glm::mat4 lightProjection = glm::ortho(-orthoSize, orthoSize, -orthoSize, orthoSize, zNear, zFar);
const glm::mat4 lightView = glm::lookAt(lightPos, target, glm::vec3(0.0f, 1.0f, 0.0f));
light_space_matrix_ = lightProjection * lightView;
```
Le shader est minimal. Il transforme les sommets directement dans l'espace de la lumi√®re. Pas besoin de fragment shader complexe,
OpenGL g√®re l'√©criture de la profondeur automatiquement.
```cpp
void main() {
    mat4 finalModel = useInstancing ? aInstanceMatrix : model;
    gl_Position = lightSpaceMatrix * finalModel * vec4(aPos, 1.0);
}
```
Voici √† quoi ressemble cette texture de profondeur captur√©e depuis la source lumineuse
![Shadow Map](/src/assets/shadow_map.png)
Une fois la texture de profondeur g√©n√©r√©e, je fais le calcul d'ombre dans mon fragment
shader principal, deferred_lit.frag. Pour √©viter le Shadow Acne (des bandes noires dues
√† l'impr√©cision du calcul), j'applique un Bias classique et un Normal Bias qui d√©pend
de l'inclinaison de la face par rapport √† la lumi√®re.
```cpp
float ShadowCalculation(vec4 fragPosLightSpace, vec3 normal, vec3 fragPos) {
    vec3 projCoords = fragPosLightSpace.xyz / fragPosLightSpace.w;
    projCoords = projCoords * 0.5 + 0.5;

    if(projCoords.z > 1.0) return 0.0;

    float currentDepth = projCoords.z;
    vec3 lightDir = normalize(-lights[0].direction);
    float bias = max(shadowBias * (1.0 - dot(normal, lightDir)), shadowBias);

    if(usePCF){
        float shadow = 0.0;
        vec2 texelSize = 1.0 / vec2(textureSize(shadowMap, 0));

        for(int x = -1; x <= 1; ++x) {
            for(int y = -1; y <= 1; ++y) {
                float pcfDepth = texture(shadowMap, projCoords.xy + vec2(x, y) * texelSize).r;
                shadow += currentDepth - bias > pcfDepth  ? 1.0 : 0.0;
            }
        }
        return shadow / 9.0;
    }

    float pcfDepth = texture(shadowMap, projCoords.xy).r;
    return currentDepth - bias > pcfDepth ? 1.0 : 0.0;
}
```
Sur cette image, l'intensit√© de la lumi√®re a √©t√© pouss√©e pour bien voir les ombres. Sans aucun filtrage, 
les bords s'arr√™tent net et l'aspect est tr√®s pixelis√©
![Shadow without PCF](/src/assets/shadow.png)
Pour corriger √ßa, j'utilise le PCF. Le principe est de faire une "photo" des ombres
autour du pixel actuel en √©chantillonnant une grille 3x3 dans la shadow map,
puis de faire la moyenne. Cela cr√©e un d√©grad√© qui adoucit les contours.
![Shadow with PCF](/src/assets/shadow_pcf.png)
M√™me avec le PCF, on voit encore parfois une forme de grille dans l'ombre. Pour corriger √ßa, j'utilise un Poisson Disk.
Au lieu de tester les pixels sur une grille carr√©e toute droite, j'utilise 16 points plac√©s de 
fa√ßon plus "al√©atoire" mais bien r√©partis. Je me suis bas√© sur ce [LearnOpenGL](https://www.opengl-tutorial.org/intermediate-tutorials/tutorial-16-shadow-mapping/#poisson-sampling) pour l'impl√©mentation.
```cpp
vec2 poissonDisk[16] = vec2[](
    vec2( -0.94201624, -0.39906216 ),
    vec2( 0.94558609, -0.76890725 ),
    vec2( -0.094184101, -0.92938870 ),
    vec2( 0.34495938, 0.29387760 ),
    vec2( -0.91588581, 0.45771432 ),
    vec2( -0.81544232, -0.87912464 ),
    vec2( -0.38277543, 0.27676845 ),
    vec2( 0.97484398, 0.75648379 ),
    vec2( 0.44323325, -0.97511554 ),
    vec2( 0.53742981, -0.47373420 ),
    vec2( -0.26496911, -0.41893023 ),
    vec2( 0.79197514, 0.19090188 ),
    vec2( -0.24188840, 0.99706507 ),
    vec2( -0.81409955, 0.91437590 ),
    vec2( 0.19984126, 0.78641367 ),
    vec2( 0.14383161, -0.14100790 )
);
```
En multipliant une valeur al√©atoire par 2œÄ (6.28318530718), je g√©n√®re un angle de rotation al√©atoire.
Cet angle sert √† faire pivoter les 16 points du disque diff√©remment pour chaque pixel.
Cela permet de "m√©langer" les samples. La fonction rand vient de cette [discussion Khronos](https://community.khronos.org/t/random-values/75728 ).
```cpp
float shadow = 0.0;
  vec2 texelSize = 1.0 / vec2(textureSize(shadowMap, 0));

  float diskRadius = 2.0;

  float angle = rand(gl_FragCoord.xy) * 6.28318530718;
  float s = sin(angle);
  float c = cos(angle);
  mat2 rotationMatrix = mat2(c, -s, s, c);

  for(int i = 0; i < 16; ++i){
      vec2 offset = rotationMatrix * poissonDisk[i];
      float pcfDepth = texture(shadowMap, projCoords.xy + offset * texelSize * diskRadius).r;
      shadow += currentDepth - bias > pcfDepth ? 1.0 : 0.0;
  }
  return shadow / 16.0;
```
Voici le r√©sultat final. L'ombre est maintenant beaucoup plus "smooth" et naturelle gr√¢ce au
m√©lange du Poisson Disk et de la rotation al√©atoire.
![Shadow with Poisson Sampling + Rotation](/src/assets/shadow_poisson.png)
# Conclusion